# -*- coding: utf-8 -*-
"""GTZAN Audio Processing

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I0z4ZXahglNzjDfsyVKFPLXUdA3bYxZp

## References

  + [Deep Learning For Audio, part 12: dataset preparation](https://github.com/musikalkemist/DeepLearningForAudioWithPython/blob/44a0e1880eee57a523780a1862cb8bf44963fbe8/12-%20Music%20genre%20classification%3A%20Preparing%20the%20dataset/code/extract_data.py)

# Setup

Use a copy of the [GTZAN music dataset](https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification) that is stored in a Google Drive folder. Reference the path to this "gtzan" dataset, and update the `DATASET_PATH` below, as necessary.
"""

from google.colab import drive
drive.mount('/content/drive')

import os

# you might need to update the path below, or create a shortcut to the path below
DATASET_PATH = '/content/drive/MyDrive/Research/DS Research Shared 2023/data/gtzan'

print(DATASET_PATH)
assert os.path.isdir(DATASET_PATH)
print(os.listdir(DATASET_PATH))

"""# Directory Traversal"""

GENRES_DIR = os.path.join(DATASET_PATH, "genres_original")

GENRES = sorted(os.listdir(GENRES_DIR))
print("GENRES:", GENRES)

for genre in GENRES:
    print("--------")
    genre_dirpath = os.path.join(GENRES_DIR, genre)
    audio_filenames = sorted(os.listdir(genre_dirpath))
    print(len(audio_filenames), audio_filenames[0], "...", audio_filenames[-1])
    for audio_filename in audio_filenames:
        # todo: process audio and get mfccs
        # todo: save mfccs
        pass

"""## Tracks"""

genre_dirpath = os.path.join(GENRES_DIR, "classical")

audio_filename = "classical.00099.wav"
audio_filepath = os.path.join(genre_dirpath, audio_filename)
print(audio_filepath)
os.path.isfile(audio_filepath)

# https://librosa.org/doc/main/generated/librosa.load.html

import librosa

SAMPLE_RATE = 22_050

track, sample_rate = librosa.load(audio_filepath, sr=SAMPLE_RATE)
print(track.shape)

# https://librosa.org/doc/main/generated/librosa.feature.mfcc.html

num_mfcc = 13
n_fft = 2_048
hop_length = 512

mfcc = librosa.feature.mfcc(track, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)
#print(mfcc.shape) #> row per mfcc

mfcc = mfcc.T
print(mfcc.shape) #>  col per mfcc

len(track) / len(mfcc) #> hop_length

len(mfcc[0])

mfcc[0]

result = {"track": audio_filename, "mfcc_shape": mfcc.shape, "mfcc": mfcc.tolist()}
print(result)

json_filename = audio_filename.replace(".wav", ".json")
json_filename



# import json
# 
# json_filepath = json_filename
# with open(json_filepath, "w") as json_file:
#     json.dump(result, json_file)
#

mfcc_dirpath = os.path.join(DATASET_PATH, "mfcc")
if not os.path.isdir(mfcc_dirpath):
    os.mkdir(mfcc_dirpath)

genre_mfcc_dirpath = os.path.join(mfcc_dirpath, "classical")
if not os.path.isdir(genre_mfcc_dirpath):
    os.mkdir(genre_mfcc_dirpath)

json_filepath = os.path.join(genre_mfcc_dirpath, json_filename)
json_filepath

import json

with open(json_filepath, "w") as json_file:
    json.dump(result, json_file)





# https://librosa.org/doc/main/generated/librosa.load.html

import librosa

SAMPLE_RATE = 22_050

def process_track(genre, audio_filename, sr=SAMPLE_RATE):
    genre_dirpath = os.path.join(GENRES_DIR, genre)
    audio_filepath = os.path.join(genre_dirpath, audio_filename)
    #print(audio_filepath)
    os.path.isfile(audio_filepath)

    # https://librosa.org/doc/main/generated/librosa.load.html
    track, sample_rate = librosa.load(audio_filepath, sr=sr)
    #print(track.shape)
    return track
    

def process_mfcc(track, sr=SAMPLE_RATE, n_mfcc=13, n_fft=2048, hop_length=512):
    # https://librosa.org/doc/main/generated/librosa.feature.mfcc.html
    mfcc = librosa.feature.mfcc(track, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)
    #print(mfcc.shape) #> row per mfcc

    mfcc = mfcc.T
    #print(mfcc.shape) #>  col per mfcc
    return mfcc

import json

MFCC_DIRPATH = os.path.join(DATASET_PATH, "mfcc")
if not os.path.isdir(MFCC_DIRPATH):
    os.mkdir(MFCC_DIRPATH)

def save_mfcc(genre, audio_filename, mfcc):
    genre_mfcc_dirpath = os.path.join(MFCC_DIRPATH, genre)
    if not os.path.isdir(genre_mfcc_dirpath):
        os.mkdir(genre_mfcc_dirpath)

    json_filename = json_filename = audio_filename.replace(".wav", ".json")
    json_filepath = os.path.join(genre_mfcc_dirpath, json_filename)

    with open(json_filepath, "w") as json_file:
        json.dump(result, json_file)

results = []

for genre in GENRES:
    genre_dirpath = os.path.join(GENRES_DIR, genre)
    
    audio_filenames = sorted(os.listdir(genre_dirpath))
    #audio_filenames = sorted([fname for fname in os.listdir(genre_dirpath)] if fname.endswith(".wav"))
    print(genre, len(audio_filenames))
    
    for audio_filename in audio_filenames:
        try:
            track = process_track(genre, audio_filename)
            
            mfcc = process_mfcc(track)
            #print(audio_filename, track.shape, mfcc.shape)
            results.append({
                "audio_filename": audio_filename,
                #"error": None,
                "track_length": len(track),
                "mfcc_rows": mfcc.shape[0],
                "mfcc_cols": mfcc.shape[1]
            })

            save_mfcc(genre, audio_filename, mfcc)
        except Exception as err:
            print("ERR:", audio_filename, err)
            #results.append({
            #    "audio_filename": audio_filename,
            #    "error": err,
            #    "track_length": None,
            #    "mfcc_rows": None,
            #    "mfcc_cols": None
            #})


from pandas import DataFrame
results_df = DataFrame(results)
results_df

results_df.to_csv(os.path.join(MFCC_DIRPATH, "results.csv"), index=False)

"""## Track Segments"""











"""## Scratch Work"""

genre_dirpath = os.path.join(GENRES_DIR, "blues")
audio_filename = "blues.00000.wav"
audio_filepath = os.path.join(genre_dirpath, audio_filename)
print(audio_filepath)
os.path.isfile(audio_filepath)

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# 
# !pip install librosa

"""### Audio Signal Processing"""

# https://github.com/musikalkemist/DeepLearningForAudioWithPython/blob/44a0e1880eee57a523780a1862cb8bf44963fbe8/12-%20Music%20genre%20classification%3A%20Preparing%20the%20dataset/code/extract_data.py


import librosa

SAMPLE_RATE = 22_050 # this is standard?

signal, sample_rate = librosa.load(audio_filepath, sr=SAMPLE_RATE)
print(type(signal), signal.shape) #> <class 'numpy.ndarray'> (661794,)
print(sample_rate) #> 22050

TRACK_DURATION = 30 # measured in seconds
SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION
print(SAMPLES_PER_TRACK) #> 661_500

num_segments = 5
samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)
print(samples_per_segment) #> 132_300

#from math import ceil
#
#hop_length = 512
#
#num_mfcc_vectors_per_segment = ceil(samples_per_segment / hop_length)
#print(num_mfcc_vectors_per_segment) #> 259

# process all segments of audio file
for i in range(num_segments):
    # calculate start and finish sample for current segment
    start = samples_per_segment * i
    finish = start + samples_per_segment

    segment = signal[start:finish]
    print(segment.shape, start, finish) #> each of n segments has length 132_300

    # extract mfcc
    #num_mfcc = 13
    #n_fft = 2048
    #mfcc = librosa.feature.mfcc(segment, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)
    #mfcc = mfcc.T
    #
    ## store only mfcc feature with expected number of vectors
    #if len(mfcc) == num_mfcc_vectors_per_segment:
    #    data["mfcc"].append(mfcc.tolist())
    #    data["labels"].append(i-1)
    #    print("{}, segment:{}".format(file_path, d+1))

segment

from math import ceil

hop_length = 512

num_mfcc_vectors_per_segment = ceil(samples_per_segment / hop_length)
print(num_mfcc_vectors_per_segment) #> 259

# extract mfcc
num_mfcc = 13
n_fft = 2048

mfcc = librosa.feature.mfcc(segment, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)
print(mfcc.shape) #> row per mfcc

mfcc = mfcc.T
print(mfcc.shape) #>  col per mfcc

print(len(mfcc), num_mfcc_vectors_per_segment)
len(mfcc) == num_mfcc_vectors_per_segment



mfcc.tolist()

print(len(mfcc.tolist()))
#print(len(max(mfcc.tolist()))) # each is length 13
#print(len(min(mfcc.tolist()))) # each is length 13
print(mfcc.tolist())

